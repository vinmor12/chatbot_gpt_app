# GPT-Neo
GPT-Neo 125M is a transformer model designed using EleutherAI's replication of the GPT-3 architecture. GPT-Neo refers to the class of models, while 125M represents the number of parameters of this particular pre-trained model.

You can find more information [here](https://huggingface.co/EleutherAI/gpt-neo-125m).
